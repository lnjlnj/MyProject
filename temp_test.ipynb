{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "\"\"\"\n",
    "create binary label\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "\n",
    "father_dir = '/home/leiningjie/PycharmProjects/dataset/advertisement_flickr30k_binary'\n",
    "path = '/home/leiningjie/PycharmProjects/dataset/advertisement_flickr30k_binary/adv_flickr_binary_label.json'\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data_test = data[:1000] + data[-1000:]\n",
    "data_train = data[:-1000]\n",
    "\n",
    "with open(f'{father_dir}/train_binary.json', 'w') as f:\n",
    "    json.dump(data_train, f)\n",
    "\n",
    "with open(f'{father_dir}/test_binary.json', 'w') as f:\n",
    "    json.dump(data_test, f)\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "csv_path = '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/vit_binary_result.csv'\n",
    "save_path = '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/test'\n",
    "df = pd.read_csv(csv_path)\n",
    "record = []\n",
    "for index, rows in df.iterrows():\n",
    "    if rows['predict'] == 1:\n",
    "        record.append(rows['image_abs_path'])\n",
    "for n in record:\n",
    "    src = n\n",
    "\n",
    "    tgt = f'{save_path}/{src.split(\"/\")[-1]}'\n",
    "    shutil.copyfile(src, tgt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "416477it [00:11, 37720.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# copy crawled laion file\n",
    "\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "csv_path_1= '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/record.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path_1)\n",
    "df_sample = df.sample(n=1000000)\n",
    "target = []\n",
    "i = 0\n",
    "for index, rows in tqdm(df_sample.iterrows()):\n",
    "    if rows['predict'] == 0:\n",
    "        i += 1\n",
    "        target.append(rows[0])\n",
    "        if i > 100000:\n",
    "            break\n",
    "\n",
    "csv_path = '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/'\n",
    "with open(f'{csv_path}/test.json', 'w') as f:\n",
    "    json.dump(target, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "path = '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/images/batch-638/4076184000789.0.jpg'\n",
    "image = Image.open(path)\n",
    "image.show()\n",
    "print(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<zip object at 0x7f5af8a2b080>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "a = [1, 2 ,3]\n",
    "b = ['a', 'b', 'c']\n",
    "\n",
    "zipped_1 = zip(a, b)\n",
    "zipped_2 = zip(a, b)\n",
    "a = str(zipped_1)\n",
    "df = pd.DataFrame({'pic_abs_path':b,\n",
    "                   'predict':a})\n",
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "# with open('./test.json', 'w') as f:\n",
    "#     json.dump(a, f)\n",
    "# with open('./test.json', 'a') as f:\n",
    "#     json.dump(b, f)\n",
    "with open('./test.txt', 'w') as f:\n",
    "    f.write(f'{str(zipped_1)}')\n",
    "with open('./test.txt', 'a') as f:\n",
    "    f.write(f'\\n{str(zipped_2)}')\n",
    "print(1)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "copy meta\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "import tqdm\n",
    "\n",
    "csv_path = '/home/leiningjie/PycharmProjects/dataset/metaphor/metaphor_with_topic_2897.csv'\n",
    "img_path = '/home/leiningjie/PycharmProjects/dataset/advertisement_flickr30k_binary/total'\n",
    "\n",
    "\n",
    "# 打开 csv 文件\n",
    "with open(csv_path, mode='r', errors='ignore') as csv_file:\n",
    "    # 读取 csv 文件内容，指定分隔符和行结束符\n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=',', lineterminator='\\n')\n",
    "    # 将内容转换为字典列表\n",
    "    result_dict = [row for row in csv_reader]\n",
    "\n",
    "id_total = []\n",
    "for n in result_dict:\n",
    "    id_total.append(n['Pic_id'])\n",
    "\n",
    "for n in tqdm.tqdm(id_total):\n",
    "    src = f'{img_path}/{n}'\n",
    "    tgt = f'/home/leiningjie/PycharmProjects/dataset/metaphor/images/{n}'\n",
    "    if os.path.exists(src) is True:\n",
    "        shutil.copyfile(src, tgt)\n",
    "    elif os.path.exists(f'/home/leiningjie/PycharmProjects/dataset/advertisment/10/{n}') is True:\n",
    "        src = f'/home/leiningjie/PycharmProjects/dataset/advertisment/10/{n}'\n",
    "        shutil.copyfile(src, tgt)\n",
    "    elif os.path.exists(f'/home/leiningjie/PycharmProjects/dataset/advertisment/9/{n}') is True:\n",
    "        src = f'/home/leiningjie/PycharmProjects/dataset/advertisment/9/{n}'\n",
    "        shutil.copyfile(src, tgt)\n",
    "\n",
    "\n",
    "print(result_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31784/31784 [00:02<00:00, 10931.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "src = '/home/leiningjie/PycharmProjects/dataset/advertisement_flickr30k_binary/flickr30k-images'\n",
    "tgt = '/home/leiningjie/PycharmProjects/dataset/advertisement_flickr30k_binary/total'\n",
    "file_name = os.listdir(src)\n",
    "for n in tqdm(file_name):\n",
    "    src_path = f'{src}/{n}'\n",
    "    tgt_path = f'{tgt}/{n}'\n",
    "    shutil.copyfile(src_path, tgt_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    /home/leiningjie/PycharmProjects/dataset/LAION...\n",
      "Name: 156377, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "json_path = '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/image_abs_paths.json'\n",
    "save_path = '/home/leiningjie/PycharmProjects/dataset/metaphor/non_meta_0.json'\n",
    "df = pd.read_json(json_path).sample(n=50000)\n",
    "df.to_json(save_path)\n",
    "for index, rows in df.iterrows():\n",
    "    print(rows)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /home/leiningjie/PycharmProjects/dataset/metaphor/non_meta_0.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      4\u001B[0m save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/leiningjie/PycharmProjects/dataset/metaphor/non_meta_0.json\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, rows \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(rows)\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pandas/io/json/_json.py:760\u001B[0m, in \u001B[0;36mread_json\u001B[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001B[0m\n\u001B[1;32m    757\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_axes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m orient \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    758\u001B[0m     convert_axes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 760\u001B[0m json_reader \u001B[38;5;241m=\u001B[39m \u001B[43mJsonReader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m    \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    765\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    766\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    767\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_default_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_default_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    768\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecise_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    769\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    772\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    773\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    774\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    775\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    776\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    777\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    778\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize:\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m json_reader\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pandas/io/json/_json.py:861\u001B[0m, in \u001B[0;36mJsonReader.__init__\u001B[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001B[0m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m filepath_or_buffer\n\u001B[1;32m    860\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mujson\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 861\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data_from_filepath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preprocess_data(data)\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/pandas/io/json/_json.py:917\u001B[0m, in \u001B[0;36mJsonReader._get_data_from_filepath\u001B[0;34m(self, filepath_or_buffer)\u001B[0m\n\u001B[1;32m    909\u001B[0m     filepath_or_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n\u001B[1;32m    910\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (\n\u001B[1;32m    911\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(filepath_or_buffer, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    912\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m filepath_or_buffer\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mendswith(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    915\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file_exists(filepath_or_buffer)\n\u001B[1;32m    916\u001B[0m ):\n\u001B[0;32m--> 917\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_or_buffer\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m filepath_or_buffer\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: File /home/leiningjie/PycharmProjects/dataset/metaphor/non_meta_0.json does not exist"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "save_path = '/home/leiningjie/PycharmProjects/dataset/metaphor/non_meta_0.json'\n",
    "df = pd.read_json(save_path)\n",
    "for index, rows in df.iterrows():\n",
    "    print(rows)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "爬取图片变为json文件\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "\n",
    "images_path = '/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/images'\n",
    "images_fold = os.listdir(images_path)\n",
    "images_abs_paths = [os.path.join(images_path, f) for f in images_fold]\n",
    "i = 0\n",
    "image = []\n",
    "for file in images_abs_paths:\n",
    "    image_path = os.listdir(file)\n",
    "    image_abs_paths = [os.path.join(file, f) for f in image_path]\n",
    "    image += image_abs_paths\n",
    "    i += len(image_abs_paths)\n",
    "with open('/home/leiningjie/PycharmProjects/dataset/LAION/LAION-2B-en/0/image_abs_paths.json', 'w') as f:\n",
    "    json.dump(image, f)\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}